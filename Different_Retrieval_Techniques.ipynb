{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ef5a150",
   "metadata": {},
   "source": [
    "## In this notebook, I have shown examples on how to use different retrieval techniques from a vector database and the challenges faced in each technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ddbba42-cc80-4f0a-a343-bcd2e79262a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import sys\n",
    "from dotenv import load_dotenv, find_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb407360-468f-45b0-9765-589c7536e099",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = load_dotenv(find_dotenv())\n",
    "import os\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1da14a3-f83c-4366-9f26-6b297d7b1de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df32efac-9f12-4680-bc13-3e3791f23965",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders = [\n",
    "    PyPDFLoader(\"docs/MachineLearning-Lecture01.pdf\"),\n",
    "    PyPDFLoader(\"docs/MachineLearning-Lecture01.pdf\"),\n",
    "    PyPDFLoader(\"docs/MachineLearning-Lecture02.pdf\"),\n",
    "    PyPDFLoader(\"docs/MachineLearning-Lecture03.pdf\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36624e8b-fded-4e54-acbc-9139b5863eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = []\n",
    "for loader in loaders:\n",
    "    docs.extend(loader.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf33a901-189b-4a3c-bac1-ab49d2a8ba43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78\n"
     ]
    }
   ],
   "source": [
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824b7aaf-6dd2-4652-908c-537bc3314a43",
   "metadata": {},
   "source": [
    "#### Using RecursiveTextSplitter to split docs with a chunk size of 1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09bb9a99-fa27-427b-90c7-2f8c63f17d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2841059-fdc1-4bc0-85c7-b8807fcfcd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "rc_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1500,\n",
    "    chunk_overlap = 150\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f60c93c-ae8c-4e70-af6b-e652589bebb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209\n"
     ]
    }
   ],
   "source": [
    "splits = rc_splitter.split_documents(docs)\n",
    "print(len(splits))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6713c13-1cd9-465e-8482-d43e55f23301",
   "metadata": {},
   "source": [
    "#### Use Embeddings to create embedding of tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea3bedf2-4bdf-442b-8768-69639f1dcff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec5a348c-b9f9-4dc1-a00b-3a79c21c1354",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a4be413-a9d1-4142-b3a7-c67d14bbfb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1 = \"My favourite animal is cat.\"\n",
    "sentence2 = \"Cats are very soft and clean animals.\"\n",
    "sentence3 = \"London is in the United Kingdom.\"\n",
    "\n",
    "embedding1 = embedding.embed_query(sentence1)\n",
    "embedding2 = embedding.embed_query(sentence2)\n",
    "embedding3 = embedding.embed_query(sentence3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2088c03a-d894-4c9e-8729-f9ed0bd9f145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8677371806643356"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.dot(embedding1, embedding2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f1a693-cb67-48d8-87c6-4fce8def6fd9",
   "metadata": {},
   "source": [
    "#### Answer close to 1 implies higher similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ffd2cb7b-4903-4fb4-8bdd-b75e66e8b392",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7552921552552395"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(embedding1, embedding3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "20d5f457-21ea-4e8d-9c57-a3f9eeae4637",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7273475085667072"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(embedding2, embedding3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab56963-cac9-487e-9787-b98d3dadd2b1",
   "metadata": {},
   "source": [
    "## Vectorstores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2915e77f-84fd-4785-ab6a-0d61b15a88b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3f9de1e1-8e2a-4f5b-9458-3215aecc7fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b1e69ff6-bb43-4868-b5a7-cac9a39e0f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_directory = \"docs/chroma\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4dd3238b-e348-4ac9-901d-c28f66e53b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf docs/chroma/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4c962995-c7bf-4aca-a9ba-0bf599c4f4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = Chroma.from_documents(documents=splits, persist_directory=persist_directory, embedding=embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cc8dbbbd-da04-4843-acb9-75a40cd42150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209\n"
     ]
    }
   ],
   "source": [
    "print(vectordb._collection.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a38434d-776e-4140-bb45-e5ad0d0d703c",
   "metadata": {},
   "source": [
    "#### Using similarity search on our vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0bec1c0e-c75c-4689-ba78-4d9f035c3baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "hits = vectordb.similarity_search(\"Is there any email where I can ask for help?\", k= 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0c4fc054-005b-42d5-9d73-12c6a957f5eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print(len(hits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "91e7dec4-58db-4ea6-bc2c-26f40e901376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'page': 5, 'source': 'docs/MachineLearning-Lecture01.pdf'}, page_content=\"cs229-qa@cs.stanford.edu. This goes to an acc ount that's read by all the TAs and me. So \\nrather than sending us email individually, if you send email to this account, it will \\nactually let us get back to you maximally quickly with answers to your questions.  \\nIf you're asking questions about homework probl ems, please say in the subject line which \\nassignment and which question the email refers to, since that will also help us to route \\nyour question to the appropriate TA or to me  appropriately and get the response back to \\nyou quickly.  \\nLet's see. Skipping ahead — let's see — for homework, one midterm, one open and term \\nproject. Notice on the honor code. So one thi ng that I think will help you to succeed and \\ndo well in this class and even help you to enjoy this cla ss more is if you form a study \\ngroup.  \\nSo start looking around where you' re sitting now or at the end of class today, mingle a \\nlittle bit and get to know your classmates. I strongly encourage you to form study groups \\nand sort of have a group of people to study with and have a group of your fellow students \\nto talk over these concepts with. You can also  post on the class news group if you want to \\nuse that to try to form a study group.  \\nBut some of the problems sets in this cla ss are reasonably difficult.  People that have \\ntaken the class before may tell you they were very difficult. And just I bet it would be \\nmore fun for you, and you'd probably have a be tter learning experience if you form a\")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hits[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f5704198-2422-4f61-afb2-18120047f7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a26da506-531f-4ec9-8787-7f9edd97c1df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'page': 5, 'source': 'docs/MachineLearning-Lecture01.pdf'}, page_content=\"cs229-qa@cs.stanford.edu. This goes to an acc ount that's read by all the TAs and me. So \\nrather than sending us email individually, if you send email to this account, it will \\nactually let us get back to you maximally quickly with answers to your questions.  \\nIf you're asking questions about homework probl ems, please say in the subject line which \\nassignment and which question the email refers to, since that will also help us to route \\nyour question to the appropriate TA or to me  appropriately and get the response back to \\nyou quickly.  \\nLet's see. Skipping ahead — let's see — for homework, one midterm, one open and term \\nproject. Notice on the honor code. So one thi ng that I think will help you to succeed and \\ndo well in this class and even help you to enjoy this cla ss more is if you form a study \\ngroup.  \\nSo start looking around where you' re sitting now or at the end of class today, mingle a \\nlittle bit and get to know your classmates. I strongly encourage you to form study groups \\nand sort of have a group of people to study with and have a group of your fellow students \\nto talk over these concepts with. You can also  post on the class news group if you want to \\nuse that to try to form a study group.  \\nBut some of the problems sets in this cla ss are reasonably difficult.  People that have \\ntaken the class before may tell you they were very difficult. And just I bet it would be \\nmore fun for you, and you'd probably have a be tter learning experience if you form a\")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hits[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a1fa6bd8-8af4-4236-812f-1bd524af1538",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding1 = embedding.embed_query(hits[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7e283a1f-6d18-4106-ae4d-d5cd517ccafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding2 = embedding.embed_query(hits[1].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e5ce9176-a65f-499d-9d73-036642a6c3d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.999999999999999"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(embedding1, embedding2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a5d6e8-5f43-4740-b2fc-9ad5c4483dcb",
   "metadata": {},
   "source": [
    "##### Answer close to 1 indicates that both the hits are same. In this case, it is approximately 1. Lets check our metadata to verify if it is giving proper results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "20a41ec7-1bdf-42cb-923b-8fa6e4e05b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "hits = vectordb.similarity_search(\"What does the article say about regression?\", k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7a3a6c28-ada9-4ea7-b41f-1b7041a54ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'page': 2, 'source': 'docs/MachineLearning-Lecture02.pdf'}\n",
      "{'page': 10, 'source': 'docs/MachineLearning-Lecture03.pdf'}\n",
      "{'page': 12, 'source': 'docs/MachineLearning-Lecture01.pdf'}\n",
      "{'page': 12, 'source': 'docs/MachineLearning-Lecture01.pdf'}\n",
      "{'page': 14, 'source': 'docs/MachineLearning-Lecture03.pdf'}\n"
     ]
    }
   ],
   "source": [
    "for hit in hits:\n",
    "    print(hit.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f25309d-b867-4c5c-bacf-131a87989f27",
   "metadata": {},
   "source": [
    "#### if we look carefully, we can see that page 12 appears twice in the search. This is because we have taken duplicate document 1 in our loader. We can call this as one of the shortcomings of similarity search technique, as it does not identify the redundant data in the search results. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b8c225-14b7-45d3-b0d7-01a6d52ad744",
   "metadata": {},
   "source": [
    "## Let us see how can we solve above problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6aa222e5-5a27-452c-b6a9-6c5be01fcaaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lark\n",
      "  Downloading lark-1.1.9-py3-none-any.whl.metadata (1.9 kB)\n",
      "Downloading lark-1.1.9-py3-none-any.whl (111 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.7/111.7 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: lark\n",
      "Successfully installed lark-1.1.9\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#pip install --quiet --upgrade lark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "28e342de-5ce2-4c0c-8e82-2581dbbda7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f0439c1a-a6c9-4e6c-9d3c-e728a40981b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb_1 = Chroma(\n",
    "    persist_directory = persist_directory,\n",
    "    embedding_function=OpenAIEmbeddings()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "13bd3016-bc63-4213-bb19-eafcb2b270ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    \"\"\"The Amanita phalloides has a large and imposing epigeous (aboveground) fruiting body (basidiocarp).\"\"\",\n",
    "    \"\"\"A mushroom with a large fruiting body is the Amanita phalloides. Some varieties are all-white.\"\"\",\n",
    "    \"\"\"A. phalloides, a.k.a Death Cap, is one of the most poisonous of all known mushrooms.\"\"\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8bd24f1c-474d-4f06-878b-d4a327aa0fc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_db = vectordb_1.from_texts(texts, embedding=OpenAIEmbeddings())\n",
    "small_db._collection.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a68a645",
   "metadata": {},
   "source": [
    "##### In similarity search, the results will be all the sentences that contain data similar to the query provided. So if you ask it about white mushrooms, it will tell you all about mushrooms and white mushroom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ae0f6d14-57fa-43e3-b74a-e1ac4c94c65a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='A mushroom with a large fruiting body is the Amanita phalloides. Some varieties are all-white.'),\n",
       " Document(page_content='The Amanita phalloides has a large and imposing epigeous (aboveground) fruiting body (basidiocarp).'),\n",
       " Document(page_content='A. phalloides, a.k.a Death Cap, is one of the most poisonous of all known mushrooms.')]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_db.search(\"Tell me something about white mushrooms?\",k=3, search_type=\"similarity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "10d94cfc-ef36-44af-a94d-a41e18f199a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='A mushroom with a large fruiting body is the Amanita phalloides. Some varieties are all-white.'),\n",
       " Document(page_content='The Amanita phalloides has a large and imposing epigeous (aboveground) fruiting body (basidiocarp).'),\n",
       " Document(page_content='A. phalloides, a.k.a Death Cap, is one of the most poisonous of all known mushrooms.')]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_db.similarity_search(\"Tell me something about white mushrooms?\",k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2d1484",
   "metadata": {},
   "source": [
    "##### Here we will see the results using maximum marginal relevance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2c91e77e-1aec-41da-bf65-498119609e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 20 is greater than number of elements in index 3, updating n_results = 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(page_content='A mushroom with a large fruiting body is the Amanita phalloides. Some varieties are all-white.'),\n",
       " Document(page_content='A. phalloides, a.k.a Death Cap, is one of the most poisonous of all known mushrooms.')]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_db.search(\"Tell me something about white mushrooms?\",k=2, search_type=\"mmr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0a07b474-806e-474a-b913-3afdc115cb19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 20 is greater than number of elements in index 3, updating n_results = 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(page_content='A mushroom with a large fruiting body is the Amanita phalloides. Some varieties are all-white.'),\n",
       " Document(page_content='A. phalloides, a.k.a Death Cap, is one of the most poisonous of all known mushrooms.')]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_db.max_marginal_relevance_search(\"Tell me something about white mushrooms?\", k=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a89d05e-1b3c-4435-9a97-8aa419f88be9",
   "metadata": {},
   "source": [
    "### Addressing Diversity: Maximum marginal relevance\n",
    "It allows us to enforce diversity in the search results.\n",
    "\n",
    "Maximum marginal relevance strives to achieve both relevance to the query and diversity among the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3d7a1a58-141c-4ab5-92ae-d5dc173059c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"what did they say about regression in the third lecture?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ce6b98a2-9d30-411b-8348-211cb7baec60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Instructor (Andrew Ng) :All right, so who thought driving could be that dramatic, right? \\nSwitch back to the chalkboard, please. I s hould say, this work was done about 15 years \\nago and autonomous driving has come a long way. So many of you will have heard of the \\nDARPA Grand Challenge, where one of my colleagues, Sebastian Thrun, the winning \\nteam's drive a car across a desert by itself.  \\nSo Alvin was, I think, absolutely amazing wo rk for its time, but autonomous driving has \\nobviously come a long way since then. So what  you just saw was an example, again, of \\nsupervised learning, and in particular it was an  example of what they  call the regression \\nproblem, because the vehicle is trying to predict a continuous value variables of a \\ncontinuous value steering directions , we call the regression problem.  \\nAnd what I want to do today is talk about our first supervised learning algorithm, and it \\nwill also be to a regression task. So for the running example that I'm going to use \\nthroughout today's lecture, you're going to retu rn to the example of  trying to predict \\nhousing prices. So here's actually a data set collected by TA, Dan Ramage, on housing \\nprices in Portland, Oregon.  \\nSo here's a dataset of a number of houses of different sizes, and here are their asking \\nprices in thousands of dollars, $200,000. And so we  can take this data and plot it, square \\nfeet, best price, and so you make your other dataset like that. And the question is, given a\""
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hits = vectordb.similarity_search(\n",
    "    question,\n",
    "    k=3,\n",
    "    filter={\"source\":\"docs/MachineLearning-Lecture02.pdf\"}\n",
    ")\n",
    "\n",
    "hits[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a4ad1ae6-0178-4086-a6a2-7c19e86c7378",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'page': 0, 'source': 'docs/MachineLearning-Lecture03.pdf'}, page_content='MachineLearning-Lecture03  \\nInstructor (Andrew Ng) :Okay. Good morning and welcome b ack to the third lecture of \\nthis class. So here’s what I want to do t oday, and some of the topics I do today may seem \\na little bit like I’m jumping, sort  of, from topic to topic, but here’s, sort of, the outline for \\ntoday and the illogical flow of ideas. In the last lecture, we  talked about linear regression \\nand today I want to talk about sort of an  adaptation of that called locally weighted \\nregression. It’s very a popular  algorithm that’s actually one of my former mentors \\nprobably favorite machine learning algorithm.  \\nWe’ll then talk about a probabl e second interpretation of linear regression and use that to \\nmove onto our first classification algorithm, which is logistic regr ession; take a brief \\ndigression to tell you about something cal led the perceptron algorithm, which is \\nsomething we’ll come back to, again, later this  quarter; and time allowing I hope to get to \\nNewton’s method, which is an algorithm fo r fitting logistic regression models.  \\nSo this is recap where we’re talking about in the previous lecture, remember the notation \\nI defined was that I used this X superscrip t I, Y superscript I to denote the I training \\nexample. And when we’re talking about linear regression or linear l east squares, we use \\nthis to denote the predicted value of “by my hypothesis H” on the input XI. And my'),\n",
       " Document(metadata={'page': 2, 'source': 'docs/MachineLearning-Lecture02.pdf'}, page_content=\"Instructor (Andrew Ng) :All right, so who thought driving could be that dramatic, right? \\nSwitch back to the chalkboard, please. I s hould say, this work was done about 15 years \\nago and autonomous driving has come a long way. So many of you will have heard of the \\nDARPA Grand Challenge, where one of my colleagues, Sebastian Thrun, the winning \\nteam's drive a car across a desert by itself.  \\nSo Alvin was, I think, absolutely amazing wo rk for its time, but autonomous driving has \\nobviously come a long way since then. So what  you just saw was an example, again, of \\nsupervised learning, and in particular it was an  example of what they  call the regression \\nproblem, because the vehicle is trying to predict a continuous value variables of a \\ncontinuous value steering directions , we call the regression problem.  \\nAnd what I want to do today is talk about our first supervised learning algorithm, and it \\nwill also be to a regression task. So for the running example that I'm going to use \\nthroughout today's lecture, you're going to retu rn to the example of  trying to predict \\nhousing prices. So here's actually a data set collected by TA, Dan Ramage, on housing \\nprices in Portland, Oregon.  \\nSo here's a dataset of a number of houses of different sizes, and here are their asking \\nprices in thousands of dollars, $200,000. And so we  can take this data and plot it, square \\nfeet, best price, and so you make your other dataset like that. And the question is, given a\"),\n",
       " Document(metadata={'page': 14, 'source': 'docs/MachineLearning-Lecture03.pdf'}, page_content='Student: It’s the lowest it –  \\nInstructor (Andrew Ng) :No, exactly. Right. So zero to the same, this is not the same, \\nright? And the reason is, in logi stic regression this is diffe rent from before, right? The \\ndefinition of this H subscript theta of XI is not the same as the definition I was using in \\nthe previous lecture. And in pa rticular this is no longer thet a transpose XI. This is not a \\nlinear function anymore. This is  a logistic function of theta transpose XI. Okay? So even \\nthough this looks cosmetically similar, even though this is similar on the surface, to the \\nBastrian descent rule I derive d last time for least squares regression this is actually a \\ntotally different learning algorithm. Okay? And it turns out that there’s actually no \\ncoincidence that you ended up with the same l earning rule. We’ll actually talk a bit more \\nabout this later when we talk about generalized linear models. But this is one of the most \\nelegant generalized learning models that we’l l see later. That even though we’re using a \\ndifferent model, you actually ended up with wh at looks like the sa me learning algorithm \\nand it’s actually no coincidence. Cool.  \\nOne last comment as part of a sort of l earning process, over here I said I take the \\nderivatives and I ended up with this line . I didn’t want to make you sit through a long \\nalgebraic derivation, but later t oday or later this week, pleas e, do go home and look at our')]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hits = vectordb.similarity_search(\n",
    "    question,\n",
    "    k=3\n",
    ")\n",
    "\n",
    "hits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2faa02c3-5e77-4a54-b796-7df0a08493e3",
   "metadata": {},
   "source": [
    "## Self-Query retriever\n",
    "- Query for carrying out vector search\n",
    "- Filter for metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "44dd4eab-09a8-4af7-8dec-0223b97a5124",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain.chains.query_constructor.base import AttributeInfo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93968d63",
   "metadata": {},
   "source": [
    "We are going to define metadata field information and attribute information here to apply filter to search results and the attribute that should be included in the search results display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "782e9329-7315-4dec-aef1-c2c1740a5a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_field_info = [\n",
    "    AttributeInfo(\n",
    "        name=\"source\",\n",
    "        description=\"The document from where the chunk is. It should be one value from 'docs/MachineLearning-Lecture01.pdf' or 'docs/MachineLearning-Lecture02.pdf' or 'docs/MachineLearning-Lecture03.pdf'\",\n",
    "        type=\"string\"\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"pageno\",\n",
    "        description=\"page number in the document from where the result is.\",\n",
    "        type=\"integer\"\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c86b2d32-534b-40d4-8905-a7118529ff1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_content_description = \"Lecture notes\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298ae898",
   "metadata": {},
   "source": [
    "We are using gpt's instruct model here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "979ee9ac-a209-4c86-acd5-3dc556bf8328",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(model='gpt-3.5-turbo-instruct', temperature=0)\n",
    "\n",
    "retreiver = SelfQueryRetriever.from_llm(\n",
    "    llm=llm,\n",
    "    vectorstore=vectordb,\n",
    "    document_contents=document_content_description,\n",
    "    metadata_field_info=metadata_field_info,\n",
    "    verbose = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a770349b-ed90-40ec-ba2e-602e681bcac4",
   "metadata": {},
   "source": [
    "#### advantage of SelfQueryRetriever is that we are not going to pass filter param while defining vector search\n",
    "Since we had defined the metadata field info, it is showing page number and source from metadata, also it has restricted search to document 1 and 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "94bbc5e8-bbbb-42a5-b214-bde81d37fc5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'page': 14, 'source': 'docs/MachineLearning-Lecture03.pdf'}\n",
      "{'page': 10, 'source': 'docs/MachineLearning-Lecture03.pdf'}\n",
      "{'page': 0, 'source': 'docs/MachineLearning-Lecture03.pdf'}\n",
      "{'page': 10, 'source': 'docs/MachineLearning-Lecture03.pdf'}\n"
     ]
    }
   ],
   "source": [
    "hits = retreiver.get_relevant_documents(question)\n",
    "\n",
    "for hit in hits:\n",
    "    print(hit.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c148b9de-f656-43fb-8b1b-17c6be2335c9",
   "metadata": {},
   "source": [
    "Another approach for improving the quality of retrieved docs is compression.\n",
    "\n",
    "Information most relevant to a query may be buried in a document with a lot of irrelevant text.\n",
    "\n",
    "Passing that full document through your application can lead to more expensive LLM calls and poorer responses.\n",
    "\n",
    "Contextual compression is meant to fix this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1dc865c7-1284-4fca-bbfe-fdc254debcf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fdceb60d-77d4-4963-8cfc-9cb7afa58451",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_docs(docs):\n",
    "    print(f\"\\n{'-' * 100}\\n\".join([f\"Document {i+1}:\\n\\n\" + d.page_content for i, d in enumerate(docs)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d7b16608-22ab-4975-bb92-d0e6cb7ed660",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressor = LLMChainExtractor.from_llm(\n",
    "    llm\n",
    ")\n",
    "\n",
    "compressor_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor,\n",
    "    base_retriever=vectordb.as_retriever()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "48371b00-4bdd-49b6-9603-fac36873ef88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='In the last lecture, we talked about linear regression and today I want to talk about sort of an adaptation of that called locally weighted regression.' metadata={'page': 0, 'source': 'docs/MachineLearning-Lecture03.pdf'}\n",
      "page_content='- \"So what you just saw was an example, again, of supervised learning, and in particular it was an example of what they call the regression problem\"\n",
      "- \"And what I want to do today is talk about our first supervised learning algorithm, and it will also be to a regression task\"\n",
      "- \"So for the running example that I'm going to use throughout today's lecture, you're going to return to the example of trying to predict housing prices\"\n",
      "- \"So here's actually a data set collected by TA, Dan Ramage, on housing prices in Portland, Oregon\"\n",
      "- \"So here's a dataset of a number of houses of different sizes, and here are their asking prices in thousands of dollars, $200,000\"' metadata={'page': 2, 'source': 'docs/MachineLearning-Lecture02.pdf'}\n",
      "page_content='Instructor (Andrew Ng) :No, exactly. Right. So zero to the same, this is not the same, \n",
      "right? And the reason is, in logi stic regression this is diffe rent from before, right? The \n",
      "definition of this H subscript theta of XI is not the same as the definition I was using in \n",
      "the previous lecture. And in pa rticular this is no longer thet a transpose XI. This is not a \n",
      "linear function anymore. This is  a logistic function of theta transpose XI. Okay? So even \n",
      "though this looks cosmetically similar, even though this is similar on the surface, to the \n",
      "Bastrian descent rule I derive d last time for least squares regression this is actually a \n",
      "totally different learning algorithm. Okay? And it turns out that there’s actually no \n",
      "coincidence that you ended up with the same l earning rule. We’ll actually talk a bit more \n",
      "about this later when we talk about generalized linear models. But this is one of the most \n",
      "elegant generalized learning models that we’l l see later. That even though we’re using a \n",
      "different model, you actually ended up with wh at looks like the sa me learning algorithm \n",
      "and it’s' metadata={'page': 14, 'source': 'docs/MachineLearning-Lecture03.pdf'}\n",
      "page_content='- locally weighted regression can run into – locally weighted regression is not a penancier for the problem  of overfitting or underfitting. You can still run into the same problems with locally weighted regression.' metadata={'page': 4, 'source': 'docs/MachineLearning-Lecture03.pdf'}\n"
     ]
    }
   ],
   "source": [
    "hits = compressor_retriever.get_relevant_documents(question)\n",
    "\n",
    "for hit in hits:\n",
    "    print(hit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e009d94f-b30e-476f-a58a-73af6d70cee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "In the last lecture, we talked about linear regression and today I want to talk about sort of an adaptation of that called locally weighted regression.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "- \"So what you just saw was an example, again, of supervised learning, and in particular it was an example of what they call the regression problem\"\n",
      "- \"And what I want to do today is talk about our first supervised learning algorithm, and it will also be to a regression task\"\n",
      "- \"So for the running example that I'm going to use throughout today's lecture, you're going to return to the example of trying to predict housing prices\"\n",
      "- \"So here's actually a data set collected by TA, Dan Ramage, on housing prices in Portland, Oregon\"\n",
      "- \"So here's a dataset of a number of houses of different sizes, and here are their asking prices in thousands of dollars, $200,000\"\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3:\n",
      "\n",
      "Instructor (Andrew Ng) :No, exactly. Right. So zero to the same, this is not the same, \n",
      "right? And the reason is, in logi stic regression this is diffe rent from before, right? The \n",
      "definition of this H subscript theta of XI is not the same as the definition I was using in \n",
      "the previous lecture. And in pa rticular this is no longer thet a transpose XI. This is not a \n",
      "linear function anymore. This is  a logistic function of theta transpose XI. Okay? So even \n",
      "though this looks cosmetically similar, even though this is similar on the surface, to the \n",
      "Bastrian descent rule I derive d last time for least squares regression this is actually a \n",
      "totally different learning algorithm. Okay? And it turns out that there’s actually no \n",
      "coincidence that you ended up with the same l earning rule. We’ll actually talk a bit more \n",
      "about this later when we talk about generalized linear models. But this is one of the most \n",
      "elegant generalized learning models that we’l l see later. That even though we’re using a \n",
      "different model, you actually ended up with wh at looks like the sa me learning algorithm \n",
      "and it’s\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 4:\n",
      "\n",
      "- locally weighted regression can run into – locally weighted regression is not a penancier for the problem  of overfitting or underfitting. You can still run into the same problems with locally weighted regression.\n"
     ]
    }
   ],
   "source": [
    "pretty_print_docs(hits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b96038-c2fe-445b-90e9-eae93fb4b202",
   "metadata": {},
   "source": [
    "### Combining compression with other types of search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "cf37d15a-ed42-45de-8d69-264d3931cd38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what did they say about regression in the third lecture?\n",
      "Document 1:\n",
      "\n",
      "In the last lecture, we talked about linear regression and today I want to talk about sort of an adaptation of that called locally weighted regression.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "- \"So what you just saw was an example, again, of supervised learning, and in particular it was an example of what they call the regression problem\"\n",
      "- \"And what I want to do today is talk about our first supervised learning algorithm, and it will also be to a regression task\"\n",
      "- \"So for the running example that I'm going to use throughout today's lecture, you're going to return to the example of trying to predict housing prices\"\n",
      "- \"So here's actually a data set collected by TA, Dan Ramage, on housing prices in Portland, Oregon\"\n",
      "- \"So here's a dataset of a number of houses of different sizes, and here are their asking prices in thousands of dollars, $200,000\"\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3:\n",
      "\n",
      "- \"linear regression model\"\n",
      "- \"distribution of the errors\"\n",
      "- \"Gaussian model\"\n",
      "- \"central limit theorem\"\n",
      "- \"sum of many independent random variables\"\n",
      "- \"error is caused by many effects\"\n",
      "- \"independent\"\n",
      "- \"sum of all these effects will be approximately Gaussian\"\n",
      "- \"reasonably accurate assumption\"\n",
      "- \"mathematically convenient\"\n",
      "- \"area around model has zero mean\"\n",
      "- \"centered around our model\"\n",
      "- \"assume what we're trying to prove\"\n",
      "- \"error has zero mean\"\n"
     ]
    }
   ],
   "source": [
    "llm = OpenAI(model=\"gpt-3.5-turbo-instruct\", temperature=0) #very precise\n",
    "\n",
    "compressor = LLMChainExtractor.from_llm(llm)\n",
    "\n",
    "compressor_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor,\n",
    "    base_retriever=vectordb.as_retriever( search_type = \"mmr\")\n",
    ")\n",
    "\n",
    "print(question)\n",
    "\n",
    "hits = compressor_retriever.get_relevant_documents(question)\n",
    "\n",
    "pretty_print_docs(hits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd99b78-4805-4205-9207-2b1c3efbd79f",
   "metadata": {},
   "source": [
    "## Other types of retrievers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "deeaf72f-f208-48bb-a872-e6521fb8e58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import TFIDFRetriever\n",
    "from langchain.retrievers import SVMRetriever\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5e2414ee-f5ed-4831-9c00-3378cfaa365a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"docs/MachineLearning-Lecture01.pdf\")\n",
    "\n",
    "pages = loader.load()\n",
    "\n",
    "all_pages_lst = [text.page_content for text in pages]\n",
    "\n",
    "all_pages_str = \" \".join(all_pages_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "cd640a89-d185-4af0-86a1-782b59b107a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60674"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_pages_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8799b49f-22f4-4ddf-8d07-736ff8de9fbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rc_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=150\n",
    ")\n",
    "\n",
    "splits = rc_splitter.split_text(all_pages_str)\n",
    "\n",
    "len(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "304c56f2-c73a-4173-b1c7-78fc691b644c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfid_retriever = TFIDFRetriever.from_texts(splits)\n",
    "svm_retriever = SVMRetriever.from_texts(splits, embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d9594504-b585-4138-83ba-cd802cfc4eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "then we want the algorithm to learn the a ssociation between the inputs and the outputs \n",
      "and to sort of give us more of the right answers, okay?  \n",
      "It turns out this specific exam ple that I drew here is an example of something called a \n",
      "regression problem. And the term regression sort of refers to the fact that the variable \n",
      "you're trying to predict is a continuous value and price.  \n",
      "There's another class of supervised learning problems which we'll talk about, which are \n",
      "classification problems. And so, in a classifi cation problem, the variab le you're trying to \n",
      "predict is discreet rather than continuous . So as one specific example — so actually a \n",
      "standard data set you can download online [i naudible] that lots of machine learning \n",
      "people have played with. Let's say you collect  a data set on breast cancer tumors, and you \n",
      "want to learn the algorithm to predict wh ether or not a certai n tumor is malignant.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "Testing, testing. Okay, cool. Thanks.   So all right, online resources. The class has a home page, so it's in on the handouts. I \n",
      "won't write on the chalkboard — http:// cs229.stanford.edu. And so when there are \n",
      "homework assignments or things like that, we  usually won't sort of — in the mission of \n",
      "saving trees, we will usually not give out many handouts in class. So homework \n",
      "assignments, homework solutions will be posted online at the course home page.  \n",
      "As far as this class, I've also written, a nd I guess I've also revised every year a set of \n",
      "fairly detailed lecture notes that cover the te chnical content of this  class. And so if you \n",
      "visit the course homepage, you'll also find the detailed lecture notes that go over in detail \n",
      "all the math and equations and so on  that I'll be doing in class.  \n",
      "There's also a newsgroup, su.class.cs229, also written on the handout. This is a \n",
      "newsgroup that's sort of a forum for people in  the class to get to  know each other and\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3:\n",
      "\n",
      "group the picture into regions. Let me actually blow that up so that you can see it more \n",
      "clearly. Okay. So in the middle, you see the lines sort of groupi ng the image together, \n",
      "grouping the image into [inaudible] regions.  \n",
      "And what Ashutosh and Min did was they then  applied the learning algorithm to say can \n",
      "we take this clustering and us e it to build a 3D model of the world? And so using the \n",
      "clustering, they then had a lear ning algorithm try to learn what the 3D structure of the \n",
      "world looks like so that they could come up with a 3D model that you can sort of fly \n",
      "through, okay? Although many people used to th ink it's not possible to take a single \n",
      "image and build a 3D model, but using a lear ning algorithm and that sort of clustering \n",
      "algorithm is the first step. They were able to.  \n",
      "I'll just show you one more example. I like this  because it's a picture of Stanford with our \n",
      "beautiful Stanford campus. So again, taking th e same sort of clustering algorithms, taking\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 4:\n",
      "\n",
      "in this classroom will not be posted online, so your images — so don't worry about being \n",
      "by seeing your own face appear on YouTube one day. But the microphones may pick up your voices, so I guess the consequence of that is that because microphones may pick up your voices, no matter how irritated you are at  me, don't yell out swear words in the \n",
      "middle of class, but because there won't be video you can safely sit there and make faces \n",
      "at me, and that won't show, okay?  \n",
      "Let's see. I also handed out this — ther e were two handouts I hope most of you have, \n",
      "course information handout. So let me just sa y a few words about parts of these. On the \n",
      "third page, there's a section that says Online Resources.  \n",
      "Oh, okay. Louder? Actually, could you turn up the volume? Testing. Is this better? \n",
      "Testing, testing. Okay, cool. Thanks.   So all right, online resources. The class has a home page, so it's in on the handouts. I\n"
     ]
    }
   ],
   "source": [
    "hits = tfid_retriever.get_relevant_documents(question)\n",
    "pretty_print_docs(hits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e53940da-9fce-44c7-a1ae-225837f5bc7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "then we want the algorithm to learn the a ssociation between the inputs and the outputs \n",
      "and to sort of give us more of the right answers, okay?  \n",
      "It turns out this specific exam ple that I drew here is an example of something called a \n",
      "regression problem. And the term regression sort of refers to the fact that the variable \n",
      "you're trying to predict is a continuous value and price.  \n",
      "There's another class of supervised learning problems which we'll talk about, which are \n",
      "classification problems. And so, in a classifi cation problem, the variab le you're trying to \n",
      "predict is discreet rather than continuous . So as one specific example — so actually a \n",
      "standard data set you can download online [i naudible] that lots of machine learning \n",
      "people have played with. Let's say you collect  a data set on breast cancer tumors, and you \n",
      "want to learn the algorithm to predict wh ether or not a certai n tumor is malignant.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "let me just check what questions you have righ t now. So if there are no questions, I'll just \n",
      "close with two reminders, which are after class today or as you start to talk with other \n",
      "people in this class, I just encourage you again to start to form project partners, to try to \n",
      "find project partners to do your project with. And also, this is a good time to start forming \n",
      "study groups, so either talk to your friends  or post in the newsgroup, but we just \n",
      "encourage you to try to star t to do both of those today, okay? Form study groups, and try \n",
      "to find two other project partners.  \n",
      "So thank you. I'm looking forward to teaching this class, and I'll see you in a couple of \n",
      "days.   [End of Audio]  \n",
      "Duration: 69 minutes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3:\n",
      "\n",
      "in this classroom will not be posted online, so your images — so don't worry about being \n",
      "by seeing your own face appear on YouTube one day. But the microphones may pick up your voices, so I guess the consequence of that is that because microphones may pick up your voices, no matter how irritated you are at  me, don't yell out swear words in the \n",
      "middle of class, but because there won't be video you can safely sit there and make faces \n",
      "at me, and that won't show, okay?  \n",
      "Let's see. I also handed out this — ther e were two handouts I hope most of you have, \n",
      "course information handout. So let me just sa y a few words about parts of these. On the \n",
      "third page, there's a section that says Online Resources.  \n",
      "Oh, okay. Louder? Actually, could you turn up the volume? Testing. Is this better? \n",
      "Testing, testing. Okay, cool. Thanks.   So all right, online resources. The class has a home page, so it's in on the handouts. I\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 4:\n",
      "\n",
      "something that was reconstructed independe ntly by yourself and w ithout referring to \n",
      "notes that you took during your  study sessions with other people, okay? And obviously, \n",
      "showing your solutions to othe rs or copying other solutions  directly is right out.  \n",
      "We occasionally also reuse problem set questions from previous years so that the \n",
      "problems are a bit more debugged and work more  smoothly. And as a result of that, I also \n",
      "ask you not to look at solutions from previous ye ars, and this includes both sort of official \n",
      "solutions that we've given out to previous gene rations of this class and previous solutions \n",
      "that people that have taken this class in previous years may have written out by \n",
      "themselves, okay?  \n",
      "Sadly, in this class, there are usually — sadly, in previous y ears, there have often been a \n",
      "few honor code violations in this class. And last year, I think I pr osecuted five honor code\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/svm/_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "hits = svm_retriever.get_relevant_documents(question)\n",
    "pretty_print_docs(hits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a608dc1b-a096-43d0-a759-c6bf6e2d2ec6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f848755-2ed0-4822-85a8-8952326ba302",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f1730a-68e6-4d32-8c9d-146d54557773",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523fc22b-cba9-4e7a-8b64-b3eab047bca9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11e6725-7b3b-4d6e-90cb-c303e6e0ac18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea83931b-f8be-4631-aa9f-e894f854ccff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
