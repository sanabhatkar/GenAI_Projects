{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3a609bd-c461-4df2-bf3c-ad6bde231638",
   "metadata": {},
   "source": [
    "## Prompt Engineering using ChatPromptTemplate and different sequential chains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0211665a-29a7-4700-946d-859ac1c11832",
   "metadata": {},
   "source": [
    "- Start by importing necessary libraries\n",
    "- read the openai api keys\n",
    "- Define LLM model using Chat GPT\n",
    "- Format prompts using ChatPromptTemplate\n",
    "- Define LLM Chain for inference\n",
    "- Examples using different types of prompt chains\n",
    "  - SimpleSequentialChain\n",
    "  - SequentialChain\n",
    "  - MultiPromptChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "099a130c-fa17-450a-aba1-70990820521e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv, find_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a853a80a-b568-40c2-978e-0a356d418588",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "109a86e2-ee7d-43ef-b1ed-ed3ee48cdae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6bf5707-6b83-40a8-96b5-f31fab52535c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def get_llm():\n",
    "    current_dt = datetime.datetime.now()\n",
    "    target_dt = datetime.datetime(2024, 6, 12)\n",
    "    if current_dt>target_dt:\n",
    "        llm_model = \"gpt-3.5-turbo\"\n",
    "    else:\n",
    "        llm_model = \"gpt-3.5-turbo-0301\"\n",
    "    return llm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16f67cf5-d684-4565-89d6-0c7ca6434e04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Queen Size Sheet Set</td>\n",
       "      <td>I ordered a king size set. My only criticism w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Waterproof Phone Pouch</td>\n",
       "      <td>I loved the waterproof sac, although the openi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Luxury Air Mattress</td>\n",
       "      <td>This mattress had a small hole in the top of i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pillows Insert</td>\n",
       "      <td>This is the best throw pillow fillers on Amazo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Milk Frother Handheld\\n</td>\n",
       "      <td>I loved this product. But they only seem to l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Product                                             Review\n",
       "0     Queen Size Sheet Set  I ordered a king size set. My only criticism w...\n",
       "1   Waterproof Phone Pouch  I loved the waterproof sac, although the openi...\n",
       "2      Luxury Air Mattress  This mattress had a small hole in the top of i...\n",
       "3           Pillows Insert  This is the best throw pillow fillers on Amazo...\n",
       "4  Milk Frother Handheld\\n   I loved this product. But they only seem to l..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"Data.csv\")\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41ac0a84-0150-4461-84d3-b5b85f2aa927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7 entries, 0 to 6\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   Product  7 non-null      object\n",
      " 1   Review   7 non-null      object\n",
      "dtypes: object(2)\n",
      "memory usage: 244.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d46b37e-9627-4c47-9035-cf17adbc36e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Queen Size Sheet Set</td>\n",
       "      <td>I ordered a king size set. My only criticism w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Waterproof Phone Pouch</td>\n",
       "      <td>I loved the waterproof sac, although the openi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Luxury Air Mattress</td>\n",
       "      <td>This mattress had a small hole in the top of i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pillows Insert</td>\n",
       "      <td>This is the best throw pillow fillers on Amazo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Milk Frother Handheld\\n</td>\n",
       "      <td>I loved this product. But they only seem to l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>L'Or Espresso Café \\n</td>\n",
       "      <td>Je trouve le goût médiocre. La mousse ne tient...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hervidor de Agua Eléctrico</td>\n",
       "      <td>Está lu bonita calienta muy rápido, es muy fun...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Product                                             Review\n",
       "0        Queen Size Sheet Set  I ordered a king size set. My only criticism w...\n",
       "1      Waterproof Phone Pouch  I loved the waterproof sac, although the openi...\n",
       "2         Luxury Air Mattress  This mattress had a small hole in the top of i...\n",
       "3              Pillows Insert  This is the best throw pillow fillers on Amazo...\n",
       "4     Milk Frother Handheld\\n   I loved this product. But they only seem to l...\n",
       "5       L'Or Espresso Café \\n  Je trouve le goût médiocre. La mousse ne tient...\n",
       "6  Hervidor de Agua Eléctrico  Está lu bonita calienta muy rápido, es muy fun..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "950869cb-7f0c-405e-a314-4432d63a8235",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e457f08-992a-4adc-abf9-996258dfafb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-3.5-turbo\n"
     ]
    }
   ],
   "source": [
    "llm_model_nm = get_llm()\n",
    "print(llm_model_nm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89f50da3-4d96-4d57-8632-cbf518997d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model=llm_model_nm,\n",
    "    temperature=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca765b4b-2c0b-4eb6-b47e-320324e99fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt = ChatPromptTemplate.from_template(\n",
    "    \"What is the best name to describe the company\\\n",
    "    that makes product {product}?\\\n",
    "\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6323d445-3304-461a-bc10-996158f601b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['product']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_prompt.messages[0].input_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbde82df-a2d6-403f-a8d4-f7ecf855b6fa",
   "metadata": {},
   "source": [
    "## LLMChain with single input and single output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "22fa1baa-0d05-4fe5-aef3-1ac618ddb217",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"TrimLife ACV Capsules\"'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = LLMChain(llm=llm, prompt=chat_prompt)\n",
    "product = \"Weight management ACV Capsules\"\n",
    "chain.run(product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b5320e24-1eba-4c2e-9632-068fb8b28032",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = data.loc[[0],['Product']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "69617147-c136-4b02-890d-53a748cbe63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in s['Product']:\n",
    "    product = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "94c8c8ec-1304-4a6e-bfaa-1a21e7d16969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queen Size Sheet Set\n"
     ]
    }
   ],
   "source": [
    "print(product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f93a1299-6179-432b-9276-b8777c27bf58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Regal Linens Co.'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = LLMChain(llm=llm, prompt=chat_prompt)\n",
    "chain.run(product)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7dc7432-a62c-448f-b339-774fa10f62d0",
   "metadata": {},
   "source": [
    "## SimpleSequentialChain with single input and single output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4288bbdd-0f79-4888-8a61-8eece57db656",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8aceca21-43dd-44d7-a3b6-f62d11468d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_prompt = ChatPromptTemplate.from_template(\"\\\n",
    "Give the best company name to describe the given product:{product}.\")\n",
    "\n",
    "second_prompt = ChatPromptTemplate.from_template(\"\\\n",
    "Write a summary of 5 lines to best describe the company:{company_name}\")\n",
    "\n",
    "first_chain = LLMChain(llm=llm, prompt=first_prompt, output_key=\"company_name\")\n",
    "second_chain = LLMChain(llm=llm, prompt=second_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "93c63135-ba18-4132-9ed6-b78e5ae407a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_chain = SimpleSequentialChain(chains=[first_chain, second_chain], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d8ae2119-f13e-4ae7-8093-db2b2212b10e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3mRegal Linens\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3mRegal Linens is a luxury linen company that specializes in creating high-quality bedding and home textiles. They offer a wide range of products including sheets, duvet covers, and towels made from premium materials. With a focus on elegance and comfort, Regal Linens provides customers with luxurious options for their home decor needs. Their products are known for their durability and softness, making them a popular choice among those seeking a touch of sophistication in their living spaces. Regal Linens is committed to providing exceptional customer service and ensuring customer satisfaction with every purchase.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Regal Linens is a luxury linen company that specializes in creating high-quality bedding and home textiles. They offer a wide range of products including sheets, duvet covers, and towels made from premium materials. With a focus on elegance and comfort, Regal Linens provides customers with luxurious options for their home decor needs. Their products are known for their durability and softness, making them a popular choice among those seeking a touch of sophistication in their living spaces. Regal Linens is committed to providing exceptional customer service and ensuring customer satisfaction with every purchase.'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_chain.run(product)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b1181d-6d8f-47c4-81ae-3ecae517a9fa",
   "metadata": {},
   "source": [
    "## SequentialChain with multiple inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "521b7a26-28df-4e27-a293-44fb9d0d7c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3dbb3052-4ae0-43e3-8ec2-6a9b5021a458",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=llm_model_nm, temperature=0.9)\n",
    "\n",
    "first_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Translate the product review given by the text into U.S. English language. Text:{review}\"\n",
    ")\n",
    "first_chain = LLMChain(llm=llm, prompt=first_prompt, output_key=\"eng_review\")\n",
    "\n",
    "second_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Summarize the given review into Pros and Cons. Review:{eng_review}\"\n",
    ")\n",
    "second_chain = LLMChain(llm=llm, prompt=second_prompt, output_key=\"summary\")\n",
    "\n",
    "third_prompt = ChatPromptTemplate.from_template(\n",
    "    \"What is the language of the review text? Review:{review}\"\n",
    ")\n",
    "third_chain = LLMChain(llm=llm, prompt=third_prompt, output_key=\"language\")\n",
    "\n",
    "fourth_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Write a follow-up response for the summary provided in the given language. Summary:{summary}, language:{language}.\"\n",
    ")\n",
    "fourth_chain = LLMChain(llm=llm, prompt=fourth_prompt, output_key=\"response_in_orig_lang\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "43f6061c-02a2-4d8d-90e3-5f6457df1da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'review': 'Está lu bonita calienta muy rápido, es muy funcional, solo falta ver cuánto dura, solo llevo 3 días en funcionamiento.',\n",
       " 'eng_review': 'Translation: It is very pretty, heats up very quickly, it is very functional, I just need to see how long it lasts, I have only been using it for 3 days.',\n",
       " 'summary': 'Pros:\\n- Very pretty design\\n- Heats up quickly\\n- Very functional\\n\\nCons:\\n- Durability is uncertain, as the reviewer has only been using it for 3 days',\n",
       " 'language': 'Spanish',\n",
       " 'response_in_orig_lang': 'Gracias por compartir tus comentarios sobre el producto. Es bueno saber que el diseño es bonito, que se calienta rápidamente y que es muy funcional. Sin embargo, es comprensible que la durabilidad sea una preocupación, especialmente después de solo 3 días de uso. Sería útil continuar probándolo para evaluar mejor su resistencia a largo plazo. ¡Esperamos que siga funcionando bien para ti en el futuro! ¡Gracias de nuevo por tu opinión!'}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_chain = SequentialChain(chains=[first_chain, second_chain, third_chain, fourth_chain], \n",
    "                                 input_variables=['review'],\n",
    "                                 output_variables=['eng_review','summary','language','response_in_orig_lang'],\n",
    "                                 verbose=True)\n",
    "\n",
    "review = data.Review[6]\n",
    "complete_chain(review)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0deca44-e5eb-4668-9fb0-f3c5940cc64b",
   "metadata": {},
   "source": [
    "## MultiPromptChain and RouterChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "246a7f14-3ec5-481a-bd3d-1fa4d819edfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "physics_template = \"\"\"\\\n",
    "You are a physics professor with an excellent academic record. You will be asked a question given by input.\\\n",
    "You have to answer as per your understanding about the topic. You are honest and you accept when you don't know the answer.\\\n",
    "Here is the question:\n",
    "{input}\n",
    "\"\"\"\n",
    "\n",
    "maths_template = \"\"\"\\\n",
    "You are a mathematician and are good at answering questions related to simple as well as complex mathematical operations.\\\n",
    "You break a mathematical equation into individual components and solve each component and combine the results for the overall answer.\\\n",
    "Here is the question:\n",
    "{input}\n",
    "\"\"\"\n",
    "\n",
    "geo_template = \"\"\"\\\n",
    "You are a very intelligent geography professor and are very good at answering questions related to geography, \\\n",
    "when you don't know an answer you reply that you don't know the answer.\\\n",
    "Here is the question:\n",
    "{input}\n",
    "\"\"\"\n",
    "\n",
    "history_template = \"\"\"\\\n",
    "You are a very knowledgable history professor and are very good at answering questions related to geography, \\\n",
    "when you don't know an answer you reply that you don't know the answer.\\\n",
    "Here is the question:\n",
    "{input}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "53ff6cdb-5903-4877-b872-b7620f9d4481",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_messages = [\n",
    "    {\n",
    "        \"name\":\"PhysicsBot\",\n",
    "        \"description\":\"Good at answering physics questions.\",\n",
    "        \"prompt_template\":physics_template\n",
    "    },\n",
    "    {\n",
    "        \"name\":\"MathsBot\",\n",
    "        \"description\":\"Good at answering maths questions.\",\n",
    "        \"prompt_template\":maths_template\n",
    "    },\n",
    "    {\n",
    "        \"name\":\"GeoBot\",\n",
    "        \"description\":\"Good at answering geography questions.\",\n",
    "        \"prompt_template\":geo_template\n",
    "    },\n",
    "    {\n",
    "        \"name\":\"HistoryBot\",\n",
    "        \"description\":\"Good at answering history questions.\",\n",
    "        \"prompt_template\":history_template\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "942439dc-494f-4fec-b6e4-cc15beb2abe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.router import MultiPromptChain\n",
    "from langchain.chains.router.llm_router import RouterOutputParser, LLMRouterChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "35f42f6a-5180-4cc6-890e-5979a67f5c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=llm_model_nm, temperature=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cd17a4b7-2519-4a1e-822e-0b74f78cb192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PhysicsBot:Good at answering physics questions.', 'MathsBot:Good at answering maths questions.', 'GeoBot:Good at answering physics questions.', 'HistoryBot:Good at answering physics questions.']\n",
      "PhysicsBot:Good at answering physics questions.\n",
      "MathsBot:Good at answering maths questions.\n",
      "GeoBot:Good at answering physics questions.\n",
      "HistoryBot:Good at answering physics questions.\n"
     ]
    }
   ],
   "source": [
    "destination_chains={}\n",
    "for prompt in prompt_messages:\n",
    "    p_name = prompt['name']\n",
    "    p_template = ChatPromptTemplate.from_template(template=prompt['prompt_template'])\n",
    "    llm_chain = LLMChain(llm=llm, prompt=p_template)\n",
    "    destination_chains[p_name]=llm_chain\n",
    "\n",
    "destinations = [f\"{p['name']}:{p['description']}\" for p in prompt_messages]\n",
    "print(destinations)\n",
    "destinations_str = \"\\n\".join(destinations)\n",
    "print(destinations_str)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0b11f5de-fcb6-4382-80b7-17d2d48f99a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_prompt = ChatPromptTemplate.from_template(\"{input}\")\n",
    "default_chain = LLMChain(llm=llm, prompt=default_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e1b35d9a-eeb1-417c-962f-059f9a6c8df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_prompt_router_template = \"\"\"Given a raw text input to a \\\n",
    "language model select the model prompt best suited for the input. \\\n",
    "You will be given the names of the available prompts and a \\\n",
    "description of what the prompt is best suited for. \\\n",
    "You may also revise the original input if you think that revising\\\n",
    "it will ultimately lead to a better response from the language model.\n",
    "\n",
    "<< FORMATTING >>\n",
    "Return a markdown code snippet with a JSON object formatted to look like:\n",
    "```json\n",
    "{{{{\n",
    "    \"destination\": string \\ name of the prompt to use or \"DEFAULT\"\n",
    "    \"next_inputs\": string \\ a potentially modified version of the original input\n",
    "}}}}\n",
    "```\n",
    "\n",
    "REMEMBER: \"destination\" MUST be one of the candidate prompt \\\n",
    "names specified below OR it can be \"DEFAULT\" if the input is not\\\n",
    "well suited for any of the candidate prompts.\n",
    "REMEMBER: \"next_inputs\" can just be the original input \\\n",
    "if you don't think any modifications are needed.\n",
    "\n",
    "<< CANDIDATE PROMPTS >>\n",
    "{destinations}\n",
    "\n",
    "<< INPUT >>\n",
    "{{input}}\n",
    "\n",
    "<< OUTPUT (remember to include the ```json)>>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ee71f950-4cf1-4016-951c-d9e54f0e4fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "router_template = multi_prompt_router_template.format(destinations=destinations_str)\n",
    "\n",
    "router_prompt = PromptTemplate(\n",
    "    template=router_template,\n",
    "    input_variables=[\"input\"],\n",
    "    output_parser=RouterOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f9f7589c-b004-40f0-b29f-77ee86557866",
   "metadata": {},
   "outputs": [],
   "source": [
    "router_chain = LLMRouterChain.from_llm(llm=llm, prompt=router_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0a4e445c-e0af-4525-9bda-8cc2c88606e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = MultiPromptChain(router_chain=router_chain,\n",
    "                        destination_chains=destination_chains,\n",
    "                        default_chain=default_chain,\n",
    "                        verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9200248f-83be-47f7-a470-6b2d3670ab28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "GeoBot: {'input': 'Which is the largest ocean in the world?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The largest ocean in the world is the Pacific Ocean.'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"Which is the largest ocean in the world?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "46f23514-f3ef-4990-bcc1-dddcb2e1afc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "PhysicsBot: {'input': \"What is Newton's second law?\"}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Newton's second law of motion states that the acceleration of an object is directly proportional to the net force acting on it and inversely proportional to its mass. In mathematical terms, this law can be expressed as F = ma, where F is the net force acting on the object, m is the mass of the object, and a is the acceleration of the object. This law essentially explains how the motion of an object changes when a force is applied to it.\""
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"What is Newton's second law?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7a91667a-e005-4b3c-bba6-1a7dcac9a3cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "None: {'input': 'Tell me recipe for pinacolada'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Ingredients:\\n- 2 oz white rum\\n- 4 oz pineapple juice\\n- 2 oz coconut cream\\n- 1 cup crushed ice\\n- Pineapple wedge and maraschino cherry for garnish\\n\\nInstructions:\\n1. In a blender, combine the white rum, pineapple juice, coconut cream, and crushed ice.\\n2. Blend until smooth and creamy.\\n3. Pour the mixture into a glass.\\n4. Garnish with a pineapple wedge and maraschino cherry.\\n5. Serve and enjoy your refreshing piña colada!'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"Tell me recipe for pinacolada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "da82281a-714e-4bb7-a9b8-dd90f6ed881a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "MathsBot: {'input': 'What is (84+104)/21'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'To solve this equation, we first need to add 84 and 104 together:\\n\\n84 + 104 = 188\\n\\nThen, we divide the sum by 21:\\n\\n188 / 21 = 8.952\\n\\nTherefore, (84+104)/21 = 8.952.'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"What is (84+104)/21\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2a3f89a2-e648-4280-a5b7-88b23990e47b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "MathsBot: {'input': 'Check if this solution is correct: 21+21=42'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'To check if the solution is correct, we need to perform the addition operation on the left side of the equation:\\n\\n21 + 21 = 42\\n\\nTherefore, the solution provided is indeed correct.'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"Check if this solution is correct: 21+21=42\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392680ec-b8af-47e6-a891-df340ea8c068",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2e973b-f965-45fd-b6b8-ebffb4c2be3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4befc63-f531-4226-82ca-0ec82d25d3b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3a916c-bdc2-4cd2-b6de-34ab177be151",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049c5f05-ae58-45db-8ea7-6fc1d6d52c2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad5ce29-0683-43f9-82f4-2c7eb1eb1c2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
